{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AKINSANYA BARAKAT AML SVMASSIGNMENT",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "1wdBPbL5L-tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from functools import reduce\n",
        "from numpy import unique, array, vectorize\n",
        "from sklearn.metrics import accuracy_score, f1_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbtZ9NGlMEkH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SVMClassifier:\n",
        "\n",
        "    def __init__(self, train_data=None):\n",
        "        self.train_step = None\n",
        "        self.sess = None\n",
        "        self.accuracy = None\n",
        "        self.loss = None\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        self.prediction = None\n",
        "        \n",
        "        data, labels = train_data\n",
        "        labels = self._transform_labels(labels)\n",
        "        data = self._flatten_input(data)\n",
        "        self.train_data = (data, labels)\n",
        "        self._open_session()\n",
        "\n",
        "        self.assemble_graph()\n",
        "\n",
        "        if train_data:\n",
        "            self.train()\n",
        "\n",
        "    def assemble_graph(self, learning_rate=0.02):\n",
        "        self.X = tf.placeholder(name=\"input\", dtype=tf.float32, shape=(None, 784))\n",
        "        self.y = tf.placeholder(name=\"label\", dtype=tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.w = tf.Variable(tf.random_normal(shape=[784, 1]))\n",
        "        self.b = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
        "\n",
        "        model_output = tf.subtract(tf.matmul(self.X, self.w), self.b)\n",
        "\n",
        "        self.loss = tf.reduce_mean(tf.maximum(0., 1 - self.y * model_output))+0.001*tf.norm(self.w)\n",
        "\n",
        "        self.prediction = tf.sign(model_output)\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(self.prediction, self.y),\n",
        "                                               tf.float32))\n",
        "\n",
        "        opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "        self.train_step = opt.minimize(self.loss)\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def train(self, epochs=20, minibatch_size=256):\n",
        "\n",
        "        data = self._create_minibatches(minibatch_size)\n",
        "        for i in range(epochs * len(data)):\n",
        "            datax, labely = data[i % len(data)]\n",
        "            self.sess.run(self.train_step, feed_dict={self.X: datax, self.y: labely})\n",
        "            train_loss = self.sess.run(self.loss, feed_dict={self.X: datax, self.y: labely})\n",
        "            accuracy = self.sess.run(self.accuracy, feed_dict={self.X: datax, self.y: labely})\n",
        "            if i % len(data) == 0:\n",
        "                print(\"Epoch %d, loss: %.2f accuracy %.2f.\" % (\n",
        "                    i // (len(data)), train_loss, accuracy))\n",
        "\n",
        "    def predict(self, data):\n",
        "        data = self._flatten_input(data)\n",
        "        pred = self.sess.run(self.prediction, feed_dict={self.X: data}).flatten()\n",
        "        pred[pred == -1] = 0\n",
        "        return pred\n",
        "\n",
        "    def _create_minibatches(self, minibatch_size):\n",
        "        pos = 0\n",
        "\n",
        "        data, labels = self.train_data\n",
        "        n_samples = len(labels)\n",
        "\n",
        "        batches = []\n",
        "        while pos + minibatch_size < n_samples:\n",
        "            batches.append((data[pos:pos + minibatch_size, :], labels[pos:pos + minibatch_size]))\n",
        "            pos += minibatch_size\n",
        "\n",
        "        if pos < n_samples:\n",
        "            batches.append((data[pos:n_samples, :], labels[pos:n_samples, :]))\n",
        "\n",
        "        return batches\n",
        "\n",
        "    def _transform_labels(self, labels):\n",
        "        labels[labels == 0] = -1\n",
        "        labels=labels.reshape((-1, 1))\n",
        "        return labels\n",
        "      \n",
        "    def _flatten_input(self, data):\n",
        "        return data.reshape((-1,784))\n",
        "\n",
        "    def _open_session(self):\n",
        "        self.sess = tf.Session()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHa0-NzdMLdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "\n",
        "    def mnist_to_binary(train_data, train_label, test_data, test_label):\n",
        "\n",
        "        binarized_labels = []\n",
        "        for labels in [train_label, test_label]:\n",
        "            remainder_2 = vectorize(lambda x: x%2)\n",
        "            binarized_labels.append(remainder_2(labels))\n",
        "\n",
        "        train_label, test_label = binarized_labels\n",
        "\n",
        "        return train_data, train_label, test_data, test_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FTOXokrtMQmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "7467a9b5-ba1f-47d7-83e4-3d061f6df80c"
      },
      "cell_type": "code",
      "source": [
        "    ((train_data, train_labels),\n",
        "        (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    train_data, train_labels, test_data, test_labels = mnist_to_binary(train_data, train_labels, eval_data, eval_labels)\n",
        "\n",
        "    svm = SVMClassifier((train_data, train_labels))\n",
        "    print(\"Testing score f1: {}\".format(f1_score(test_labels, svm.predict(test_data))))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 3848.55 accuracy 0.53.\n",
            "Epoch 1, loss: 218.74 accuracy 0.89.\n",
            "Epoch 2, loss: 187.51 accuracy 0.90.\n",
            "Epoch 3, loss: 232.38 accuracy 0.89.\n",
            "Epoch 4, loss: 202.02 accuracy 0.89.\n",
            "Epoch 5, loss: 232.95 accuracy 0.88.\n",
            "Epoch 6, loss: 227.90 accuracy 0.89.\n",
            "Epoch 7, loss: 174.33 accuracy 0.89.\n",
            "Epoch 8, loss: 182.48 accuracy 0.90.\n",
            "Epoch 9, loss: 175.23 accuracy 0.89.\n",
            "Epoch 10, loss: 194.31 accuracy 0.90.\n",
            "Epoch 11, loss: 233.72 accuracy 0.90.\n",
            "Epoch 12, loss: 234.94 accuracy 0.90.\n",
            "Epoch 13, loss: 187.25 accuracy 0.89.\n",
            "Epoch 14, loss: 191.88 accuracy 0.89.\n",
            "Epoch 15, loss: 173.04 accuracy 0.89.\n",
            "Epoch 16, loss: 183.25 accuracy 0.91.\n",
            "Epoch 17, loss: 189.04 accuracy 0.89.\n",
            "Epoch 18, loss: 186.86 accuracy 0.89.\n",
            "Epoch 19, loss: 182.48 accuracy 0.89.\n",
            "Testing score f1: 0.892829457364341\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}